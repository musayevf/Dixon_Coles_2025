{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Necessary Libraries AND Getting Today's Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from scipy.stats import poisson\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Get today's date\n",
    "given_date = \"2025-06-09\" #year-month-day\n",
    "threshold = 70 #threshold for percentages to highlight in final dataframe (between 1 and 100)\n",
    "\n",
    "wanted_leagues = ['argentina','austria', 'australia', 'belgium', 'brazil', 'colombia','denmark', \n",
    "                  'england', 'england2', 'england3', 'england4', 'england5', 'france', 'france2',\n",
    "                  'germany', 'germany2', 'greece', 'italy', 'italy2', 'japan', 'southkorea', 'usa',\n",
    "                   'mexico2', 'netherlands', 'norway','poland', 'portugal', 'portugal2',\n",
    "                   'saudiarabia','scotland', 'spain', 'spain2', 'sweden', 'switzerland', 'turkey']\n",
    "# urug, peru, ecuado,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Days between given date and today\n",
    "# Today's date\n",
    "today = datetime.now().date()\n",
    "\n",
    "# Specific date\n",
    "specific_date = datetime.strptime(given_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Calculate the difference in days\n",
    "difference = specific_date - today\n",
    "\n",
    "# Add one day to the difference\n",
    "days_until_specific_date = difference.days + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Today's Matches and Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.soccerstats.com/matches.asp?matchday=\" + str(days_until_specific_date) + \"&listing=2\"\n",
    "page = requests.get(URL)\n",
    "liqa = []\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"btable\")\n",
    "sth = results.find_all(\"tr\", attrs={'height': '34'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Date and Collecting Leagues for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mo 9 Jun\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "day_abbreviations = {0: \"Mo\", 1: \"Tu\", 2: \"We\", 3: \"Th\", 4: \"Fr\", 5: \"Sa\", 6: \"Su\"}\n",
    "given_date_parsed = parser.parse(given_date)\n",
    "\n",
    "# Manually format the day to remove leading zeros\n",
    "day = given_date_parsed.day\n",
    "month = given_date_parsed.strftime('%b')\n",
    "\n",
    "# Format the date as \"Su 1 Oct\" or \"Tu 10 Oct\" without leading zero for single-digit days\n",
    "formatted_date = f\"{day_abbreviations[given_date_parsed.weekday()]} {day} {month}\"\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web for the League Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTTG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTTG</th>\n",
       "      <th>latest_date</th>\n",
       "      <th>time_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Godoy Cruz</td>\n",
       "      <td>Rosario Central</td>\n",
       "      <td>0 - 3</td>\n",
       "      <td>(0-2)</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Tigre</td>\n",
       "      <td>Velez Sarsfield</td>\n",
       "      <td>3 - 0</td>\n",
       "      <td>(2-0)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Defensa y J.</td>\n",
       "      <td>Banfield</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Lanus</td>\n",
       "      <td>D. Riestra</td>\n",
       "      <td>0 - 2</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Newells</td>\n",
       "      <td>I. Rivadavia</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10116</th>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Rizespor</td>\n",
       "      <td>Hatayspor</td>\n",
       "      <td>5 - 2</td>\n",
       "      <td>(1-0)</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10117</th>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Adana Demirspor</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>2 - 2</td>\n",
       "      <td>(2-1)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10118</th>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Alanyaspor</td>\n",
       "      <td>Sivasspor</td>\n",
       "      <td>2 - 0</td>\n",
       "      <td>(1-0)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10119</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Bodrumspor</td>\n",
       "      <td>Besiktas</td>\n",
       "      <td>0 - 4</td>\n",
       "      <td>(0-3)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Samsunspor</td>\n",
       "      <td>Kayserispor</td>\n",
       "      <td>2 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     League             Home             Away     FT     HT  \\\n",
       "0     2025-01-23  Argentina       Godoy Cruz  Rosario Central  0 - 3  (0-2)   \n",
       "1     2025-01-23  Argentina            Tigre  Velez Sarsfield  3 - 0  (2-0)   \n",
       "2     2025-01-24  Argentina     Defensa y J.         Banfield  0 - 1  (0-0)   \n",
       "3     2025-01-24  Argentina            Lanus       D. Riestra  0 - 2  (0-0)   \n",
       "4     2025-01-24  Argentina          Newells     I. Rivadavia  0 - 1  (0-1)   \n",
       "10116 2025-05-31     Turkey         Rizespor        Hatayspor  5 - 2  (1-0)   \n",
       "10117 2025-05-31     Turkey  Adana Demirspor        Gaziantep  2 - 2  (2-1)   \n",
       "10118 2025-05-31     Turkey       Alanyaspor        Sivasspor  2 - 0  (1-0)   \n",
       "10119 2025-06-01     Turkey       Bodrumspor         Besiktas  0 - 4  (0-3)   \n",
       "10120 2025-06-01     Turkey       Samsunspor      Kayserispor  2 - 1  (0-0)   \n",
       "\n",
       "       FTHG  FTAG  FTTG  HTHG  HTAG  HTTG latest_date  time_diff  \n",
       "0         0     3     3     0     2     2  2025-05-05        102  \n",
       "1         3     0     3     2     0     2  2025-05-05        102  \n",
       "2         0     1     1     0     0     0  2025-05-05        101  \n",
       "3         0     2     2     0     0     0  2025-05-05        101  \n",
       "4         0     1     1     0     1     1  2025-05-05        101  \n",
       "10116     5     2     7     1     0     1  2025-06-01          1  \n",
       "10117     2     2     4     2     1     3  2025-06-01          1  \n",
       "10118     2     0     2     1     0     1  2025-06-01          1  \n",
       "10119     0     4     4     0     3     3  2025-06-01          0  \n",
       "10120     2     1     3     0     0     0  2025-06-01          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final =  pd.DataFrame()\n",
    "liqa = ''\n",
    "unique_leagues = wanted_leagues\n",
    "next_matches = pd.DataFrame()\n",
    "\n",
    "for i in unique_leagues:\n",
    "    URL = \"https://www.soccerstats.com/results.asp?league=\" + i + \"&pmtype=bydate\"\n",
    "    page = requests.get(URL)\n",
    "    liqa = i\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"btable\")\n",
    "    sth = results.find_all(\"tr\", class_=\"odd\")\n",
    "    sth\n",
    "\n",
    "\n",
    "    date, league, home, away, ft, ht = [], [], [], [], [],[]\n",
    "    for i in sth:\n",
    "        date.append(i.find_all(\"td\", align = 'right')[0].get_text(strip=True))\n",
    "        league.append(liqa.capitalize())\n",
    "        home.append(i.find_all(\"td\", align = 'right')[1].get_text(strip=True))\n",
    "        away.append(i.find(\"td\", align = \"left\").get_text(strip = True))\n",
    "        ft.append(i.find_all(\"td\", align = 'center')[0].get_text(strip = True))\n",
    "        try:\n",
    "            ht.append(i.find_all(\"td\", align = 'center')[2].get_text(strip = True))\n",
    "        except IndexError as e:\n",
    "            ht.append('NA')#print(\"Last output before error occurred:\", i.find_all(\"td\", align = 'center'))\n",
    "\n",
    "    data = {'Date': date, 'League': league,'Home': home, 'Away': away, 'FT': ft, 'HT': ht}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "    next_df = df[(df['Date'] == formatted_date) & (df['HT'] == '')]\n",
    "    next_matches = pd.concat([next_matches, next_df], ignore_index = True)\n",
    "    df.replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "    df_cleaned = df.dropna()\n",
    "\n",
    "#For Half-Time Results\n",
    "    hthg, htag = [], []\n",
    "    for i in df_cleaned['HT']:\n",
    "        if i == 'NA':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        elif i == '+' or i == '-':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hthg.append(int(i[1]))\n",
    "                htag.append(int(i[3]))\n",
    "            except IndexError as e:\n",
    "                print(\"Last output before error occurred:\", i)\n",
    "\n",
    "\n",
    "\n",
    "#For Full-Time Results\n",
    "    hg, ag, tg = [], [], []\n",
    "    for i in df_cleaned['FT']:\n",
    "        if len(i) < 5 or ':' in i:\n",
    "            hg.append('NA')\n",
    "            ag.append('NA')\n",
    "            tg.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hghg = int(i.split(' - ')[0])\n",
    "                hg.append(hghg)\n",
    "                agag = int(i.split(' - ')[1])\n",
    "                ag.append(agag)\n",
    "                tg.append(hghg + agag)\n",
    "            except:\n",
    "                print(hghg + agag)\n",
    "\n",
    "    \n",
    "    df_cleaned['FTHG'], df_cleaned['FTAG'], df_cleaned['FTTG'] = hg, ag, tg\n",
    "    df_cleaned['HTHG'], df_cleaned['HTAG'] = hthg, htag\n",
    "    df_cleaned['HTTG'] = df_cleaned['HTHG'] + df_cleaned['HTAG']\n",
    "    \n",
    "    final = pd.concat([final, df_cleaned], ignore_index=True)\n",
    "    \n",
    "final = final[final['HT'] != 'NA']\n",
    "\n",
    "# Define current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Function to parse and assign the correct year\n",
    "def parse_date(date_str):\n",
    "    # Extract day and month\n",
    "    date_obj = datetime.strptime(date_str[3:], '%d %b')\n",
    "    # Assign correct year\n",
    "    full_date = date_obj.replace(year=current_year)\n",
    "    \n",
    "    # If the parsed date is already in the future, assign the previous year\n",
    "    if full_date > datetime.now():\n",
    "        full_date = full_date.replace(year=current_year - 1)\n",
    "    \n",
    "    return full_date\n",
    "\n",
    "# Apply the function to parse dates\n",
    "final['Date'] = final['Date'].apply(parse_date)\n",
    "\n",
    "# Find the latest date for each league\n",
    "latest_dates = final.groupby('League')['Date'].max().rename('latest_date')\n",
    "\n",
    "# Merge with the original DataFrame\n",
    "final = final.merge(latest_dates, on='League')\n",
    "\n",
    "# Calculate the time difference in days\n",
    "final['time_diff'] = (final['latest_date'] - final['Date']).dt.days\n",
    "combined_df = pd.concat([final.head(), final.tail()])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Portland</td>\n",
       "      <td>St. Louis City</td>\n",
       "      <td>00:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Los Angeles FC</td>\n",
       "      <td>Sporting KC</td>\n",
       "      <td>02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Portland</td>\n",
       "      <td>St. Louis City</td>\n",
       "      <td>00:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Los Angeles FC</td>\n",
       "      <td>Sporting KC</td>\n",
       "      <td>02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo 9 Jun</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>02:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date League            Home            Away     FT HT\n",
       "0  Mo 9 Jun    Usa        Portland  St. Louis City  00:00   \n",
       "1  Mo 9 Jun    Usa  Los Angeles FC     Sporting KC  02:00   \n",
       "2  Mo 9 Jun    Usa       Vancouver         Seattle  02:00   \n",
       "0  Mo 9 Jun    Usa        Portland  St. Louis City  00:00   \n",
       "1  Mo 9 Jun    Usa  Los Angeles FC     Sporting KC  02:00   \n",
       "2  Mo 9 Jun    Usa       Vancouver         Seattle  02:00   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_leagues = next_matches['League'].unique().tolist()\n",
    "pd.concat([next_matches.head(), next_matches.tail()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Functions Needed for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    if x==0 and y==0:\n",
    "        return 1- (lambda_x * mu_y * rho)\n",
    "    elif x==0 and y==1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x==1 and y==0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x==1 and y==1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "    return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "            np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "def solve_parameters_decay(dataset, half_or_full = 'full', xi=0.001, debug = False, init_vals=None, \n",
    "                           options={'disp': True, 'maxiter':100},\n",
    "                     constraints = [{'type':'eq', 'fun': lambda x: sum(x[:20])-20}] , **kwargs):\n",
    "    teams = np.sort(dataset['Home'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['Away'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Home Teams Not Equal to Away Teams\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1,(n_teams)), # attack strength\n",
    "                                      np.random.uniform(0,-1,(n_teams)), # defence strength\n",
    "                                      np.array([0,1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                     ))\n",
    "        \n",
    "    def dc_log_like_decay(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma, t, xi=xi):\n",
    "        lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "        return  np.exp(-xi*t) * (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "                                  np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "    def estimate_paramters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams:(2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        if half_or_full == 'full':\n",
    "            log_like = [dc_log_like_decay(row.FTHG, row.FTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                                      score_coefs[row.Away], defend_coefs[row.Away], \n",
    "                                      rho, gamma, row.time_diff, xi=xi) for row in dataset.itertuples()]\n",
    "        elif half_or_full == 'half':\n",
    "            log_like = [dc_log_like_decay(row.HTHG, row.HTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                                      score_coefs[row.Away], defend_coefs[row.Away], \n",
    "                                      rho, gamma, row.time_diff, xi=xi) for row in dataset.itertuples()]\n",
    "        return -sum(log_like)\n",
    "    opt_output = minimize(estimate_paramters, init_vals, options=options, constraints = constraints)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                        opt_output.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Lambda Values for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 696.8021551153387\n",
      "            Iterations: 99\n",
      "            Function evaluations: 6360\n",
      "            Gradient evaluations: 99\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 473.73749608319144\n",
      "            Iterations: 85\n",
      "            Function evaluations: 5465\n",
      "            Gradient evaluations: 85\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "stats_df = pd.DataFrame()\n",
    "full_time_models = []\n",
    "half_time_models = []\n",
    "\n",
    "for league in next_leagues:\n",
    "    league_df = final[final['League'] == league.capitalize()]\n",
    "    \n",
    "    full_time_estimates = solve_parameters_decay(league_df, half_or_full = 'full')\n",
    "    full_time_models.append(full_time_estimates)\n",
    "\n",
    "    half_time_estimates = solve_parameters_decay(league_df, half_or_full = 'half')\n",
    "    half_time_models.append(half_time_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_Atlanta Utd': 0.976922534766988,\n",
       " 'attack_Austin': 0.3630081056200655,\n",
       " 'attack_CF Montreal': 0.44203587043758236,\n",
       " 'attack_Charlotte': 1.1982273634361162,\n",
       " 'attack_Chicago Fire': 1.52805352166713,\n",
       " 'attack_Cincinnati': 1.076473229538114,\n",
       " 'attack_Colorado Rapids': 0.7387598748870906,\n",
       " 'attack_Columbus Crew': 1.1284704255560094,\n",
       " 'attack_DC United': 0.6563946201180669,\n",
       " 'attack_Dallas': 0.8039696342363608,\n",
       " 'attack_Houston Dynamo': 0.9350164033491863,\n",
       " 'attack_Inter Miami': 1.5505239472284076,\n",
       " 'attack_LA Galaxy': 0.5850728770356166,\n",
       " 'attack_Los Angeles FC': 1.287749713149072,\n",
       " 'attack_Minnesota Utd': 1.1303892177972652,\n",
       " 'attack_Nashville SC': 1.2812124501180167,\n",
       " 'attack_New England': 0.9906939569583016,\n",
       " 'attack_New York City': 0.8860302705442334,\n",
       " 'attack_New York RB': 1.1460231865824098,\n",
       " 'attack_Orlando City': 1.2949718351348052,\n",
       " 'attack_Philadelphia': 1.2891470801269351,\n",
       " 'attack_Portland': 1.0736238866879726,\n",
       " 'attack_Real Salt Lake': 0.6297210691052928,\n",
       " 'attack_SJ Earthquakes': 1.3150167673001651,\n",
       " 'attack_San Diego': 1.158580256579153,\n",
       " 'attack_Seattle': 1.0780659955777077,\n",
       " 'attack_Sporting KC': 1.1340093334545356,\n",
       " 'attack_St. Louis City': 0.4790020296711811,\n",
       " 'attack_Toronto': 0.7768964018597048,\n",
       " 'attack_Vancouver': 1.2711378064536547,\n",
       " 'defence_Atlanta Utd': -0.6662379155732585,\n",
       " 'defence_Austin': -1.0391856456829154,\n",
       " 'defence_CF Montreal': -0.664494992363446,\n",
       " 'defence_Charlotte': -0.7868979521344563,\n",
       " 'defence_Chicago Fire': -0.5880068732812719,\n",
       " 'defence_Cincinnati': -0.8147077077376702,\n",
       " 'defence_Colorado Rapids': -0.723254673529397,\n",
       " 'defence_Columbus Crew': -0.8530320950611839,\n",
       " 'defence_DC United': -0.5266876006414598,\n",
       " 'defence_Dallas': -0.7330129081230267,\n",
       " 'defence_Houston Dynamo': -0.7542560544473864,\n",
       " 'defence_Inter Miami': -0.6861070048723202,\n",
       " 'defence_LA Galaxy': -0.4284675755240579,\n",
       " 'defence_Los Angeles FC': -0.717516636327633,\n",
       " 'defence_Minnesota Utd': -1.1362017889852578,\n",
       " 'defence_Nashville SC': -0.9102069210728397,\n",
       " 'defence_New England': -1.2636158715219477,\n",
       " 'defence_New York City': -1.0731499153069555,\n",
       " 'defence_New York RB': -1.05519560039301,\n",
       " 'defence_Orlando City': -0.9368336727702113,\n",
       " 'defence_Philadelphia': -1.075714533624923,\n",
       " 'defence_Portland': -0.7752459081206993,\n",
       " 'defence_Real Salt Lake': -0.7373990370314654,\n",
       " 'defence_SJ Earthquakes': -0.6088518798885721,\n",
       " 'defence_San Diego': -0.839022184552625,\n",
       " 'defence_Seattle': -0.8878684041692997,\n",
       " 'defence_Sporting KC': -0.5245499106671813,\n",
       " 'defence_St. Louis City': -0.8894381182422055,\n",
       " 'defence_Toronto': -0.8500861839205246,\n",
       " 'defence_Vancouver': -1.1505250468337644,\n",
       " 'rho': -0.1130740796664255,\n",
       " 'home_adv': 0.21133188409700218}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_time_models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probability Matrices for Half/Full Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21106312e-01, 6.66137563e-02, 2.97658422e-02, 7.37802017e-03,\n",
       "        1.37158512e-03, 2.03983801e-04, 2.52805982e-05, 2.68554371e-06,\n",
       "        2.49623321e-07],\n",
       "       [1.46450140e-01, 1.32342842e-01, 4.42068234e-02, 1.09574872e-02,\n",
       "        2.03701346e-03, 3.02947109e-04, 3.75455509e-05, 3.98844272e-06,\n",
       "        3.70728770e-07],\n",
       "       [1.18733865e-01, 8.82912213e-02, 3.28269434e-02, 8.13677132e-03,\n",
       "        1.51263811e-03, 2.24961372e-04, 2.78804397e-05, 2.96172341e-06,\n",
       "        2.75294433e-07],\n",
       "       [5.87793102e-02, 4.37086511e-02, 1.62510088e-02, 4.02811620e-03,\n",
       "        7.48832900e-04, 1.11367336e-04, 1.38022376e-05, 1.46620392e-06,\n",
       "        1.36284765e-07],\n",
       "       [2.18240641e-02, 1.62285062e-02, 6.03380775e-03, 1.49559200e-03,\n",
       "        2.78032817e-04, 4.13493773e-05, 5.12460789e-06, 5.44384210e-07,\n",
       "        5.06009244e-08],\n",
       "       [6.48241391e-03, 4.82036224e-03, 1.79222528e-03, 4.44236524e-04,\n",
       "        8.25842424e-05, 1.22820286e-05, 1.52216514e-06, 1.61698745e-07,\n",
       "        1.50300208e-08],\n",
       "       [1.60456251e-03, 1.19316240e-03, 4.43621394e-04, 1.09959852e-04,\n",
       "        2.04417029e-05, 3.04011482e-06, 3.76774632e-07, 4.00245569e-08,\n",
       "        3.72031287e-09],\n",
       "       [3.40431497e-04, 2.53146923e-04, 9.41207927e-05, 2.33295972e-05,\n",
       "        4.33700743e-06, 6.45004999e-07, 7.99382706e-08, 8.49179745e-09,\n",
       "        7.89319002e-10],\n",
       "       [6.31990983e-05, 4.69952323e-05, 1.74729697e-05, 4.33100202e-06,\n",
       "        8.05139834e-07, 1.19741371e-07, 1.48400682e-08, 1.57645208e-09,\n",
       "        1.46532414e-10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Function needs work to make it more understandable and a df rather than matrix!\n",
    "def dixon_coles_simulate_match(params_dict, homeTeam, awayTeam, max_goals=10):\n",
    "    team_avgs = [np.exp(params_dict['attack_'+homeTeam] + params_dict['defence_'+awayTeam] + params_dict['home_adv']),\n",
    "                 np.exp(params_dict['defence_'+homeTeam] + params_dict['attack_'+awayTeam])]\n",
    "    team_pred = [[poisson.pmf(i, team_avg) for i in range(0, max_goals+1)] for team_avg in team_avgs]\n",
    "    output_matrix = np.outer(np.array(team_pred[0]), np.array(team_pred[1]))\n",
    "    correction_matrix = np.array([[rho_correction(home_goals, away_goals, team_avgs[0],\n",
    "                                                   team_avgs[1], params_dict['rho']) for away_goals in range(2)]\n",
    "                                   for home_goals in range(2)])\n",
    "    output_matrix[:2,:2] = output_matrix[:2,:2] * correction_matrix\n",
    "    return output_matrix\n",
    "\n",
    "full_time_matrices = []\n",
    "half_time_matrices = []\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_league = next_matches['League'].iloc[i]\n",
    "    league_index = next_leagues.index(my_league)\n",
    "    ft_match_score_matrix = dixon_coles_simulate_match(full_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 8)\n",
    "    ht_match_score_matrix = dixon_coles_simulate_match(half_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 4)\n",
    "    full_time_matrices.append(ft_match_score_matrix)\n",
    "    half_time_matrices.append(ht_match_score_matrix)\n",
    "\n",
    "full_time_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probabilities of Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_474b5_row0_col7, #T_474b5_row0_col8, #T_474b5_row0_col12, #T_474b5_row0_col13, #T_474b5_row0_col19, #T_474b5_row0_col21, #T_474b5_row0_col23, #T_474b5_row0_col24, #T_474b5_row0_col28, #T_474b5_row0_col29, #T_474b5_row1_col7, #T_474b5_row1_col8, #T_474b5_row1_col10, #T_474b5_row1_col11, #T_474b5_row1_col14, #T_474b5_row1_col19, #T_474b5_row1_col22, #T_474b5_row1_col24, #T_474b5_row1_col25, #T_474b5_row1_col26, #T_474b5_row1_col29, #T_474b5_row2_col7, #T_474b5_row2_col8, #T_474b5_row2_col10, #T_474b5_row2_col12, #T_474b5_row2_col13, #T_474b5_row2_col19, #T_474b5_row2_col22, #T_474b5_row2_col24, #T_474b5_row2_col28, #T_474b5_row2_col29 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_474b5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_474b5_level0_col0\" class=\"col_heading level0 col0\" >League</th>\n",
       "      <th id=\"T_474b5_level0_col1\" class=\"col_heading level0 col1\" >Home</th>\n",
       "      <th id=\"T_474b5_level0_col2\" class=\"col_heading level0 col2\" >Away</th>\n",
       "      <th id=\"T_474b5_level0_col3\" class=\"col_heading level0 col3\" >FT1</th>\n",
       "      <th id=\"T_474b5_level0_col4\" class=\"col_heading level0 col4\" >FTX</th>\n",
       "      <th id=\"T_474b5_level0_col5\" class=\"col_heading level0 col5\" >FT2</th>\n",
       "      <th id=\"T_474b5_level0_col6\" class=\"col_heading level0 col6\" >FTR</th>\n",
       "      <th id=\"T_474b5_level0_col7\" class=\"col_heading level0 col7\" >DC1X</th>\n",
       "      <th id=\"T_474b5_level0_col8\" class=\"col_heading level0 col8\" >DC12</th>\n",
       "      <th id=\"T_474b5_level0_col9\" class=\"col_heading level0 col9\" >DCX2</th>\n",
       "      <th id=\"T_474b5_level0_col10\" class=\"col_heading level0 col10\" >1.5O</th>\n",
       "      <th id=\"T_474b5_level0_col11\" class=\"col_heading level0 col11\" >2.5O</th>\n",
       "      <th id=\"T_474b5_level0_col12\" class=\"col_heading level0 col12\" >3.5U</th>\n",
       "      <th id=\"T_474b5_level0_col13\" class=\"col_heading level0 col13\" >4.5U</th>\n",
       "      <th id=\"T_474b5_level0_col14\" class=\"col_heading level0 col14\" >BTTS</th>\n",
       "      <th id=\"T_474b5_level0_col15\" class=\"col_heading level0 col15\" >HT1</th>\n",
       "      <th id=\"T_474b5_level0_col16\" class=\"col_heading level0 col16\" >HTX</th>\n",
       "      <th id=\"T_474b5_level0_col17\" class=\"col_heading level0 col17\" >HT2</th>\n",
       "      <th id=\"T_474b5_level0_col18\" class=\"col_heading level0 col18\" >HTR</th>\n",
       "      <th id=\"T_474b5_level0_col19\" class=\"col_heading level0 col19\" >HTDC1X</th>\n",
       "      <th id=\"T_474b5_level0_col20\" class=\"col_heading level0 col20\" >HTDC12</th>\n",
       "      <th id=\"T_474b5_level0_col21\" class=\"col_heading level0 col21\" >HTDCX2</th>\n",
       "      <th id=\"T_474b5_level0_col22\" class=\"col_heading level0 col22\" >HT0.5O</th>\n",
       "      <th id=\"T_474b5_level0_col23\" class=\"col_heading level0 col23\" >HT1.5U</th>\n",
       "      <th id=\"T_474b5_level0_col24\" class=\"col_heading level0 col24\" >H0.5O</th>\n",
       "      <th id=\"T_474b5_level0_col25\" class=\"col_heading level0 col25\" >A0.5O</th>\n",
       "      <th id=\"T_474b5_level0_col26\" class=\"col_heading level0 col26\" >H1.5O</th>\n",
       "      <th id=\"T_474b5_level0_col27\" class=\"col_heading level0 col27\" >A1.5O</th>\n",
       "      <th id=\"T_474b5_level0_col28\" class=\"col_heading level0 col28\" >H2.5U</th>\n",
       "      <th id=\"T_474b5_level0_col29\" class=\"col_heading level0 col29\" >A2.5U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_474b5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_474b5_row0_col0\" class=\"data row0 col0\" >Usa</td>\n",
       "      <td id=\"T_474b5_row0_col1\" class=\"data row0 col1\" >Portland</td>\n",
       "      <td id=\"T_474b5_row0_col2\" class=\"data row0 col2\" >St. Louis City</td>\n",
       "      <td id=\"T_474b5_row0_col3\" class=\"data row0 col3\" >53.560000</td>\n",
       "      <td id=\"T_474b5_row0_col4\" class=\"data row0 col4\" >29.060000</td>\n",
       "      <td id=\"T_474b5_row0_col5\" class=\"data row0 col5\" >17.370000</td>\n",
       "      <td id=\"T_474b5_row0_col6\" class=\"data row0 col6\" >1-0</td>\n",
       "      <td id=\"T_474b5_row0_col7\" class=\"data row0 col7\" >82.620000</td>\n",
       "      <td id=\"T_474b5_row0_col8\" class=\"data row0 col8\" >70.930000</td>\n",
       "      <td id=\"T_474b5_row0_col9\" class=\"data row0 col9\" >46.430000</td>\n",
       "      <td id=\"T_474b5_row0_col10\" class=\"data row0 col10\" >66.580000</td>\n",
       "      <td id=\"T_474b5_row0_col11\" class=\"data row0 col11\" >38.500000</td>\n",
       "      <td id=\"T_474b5_row0_col12\" class=\"data row0 col12\" >81.370000</td>\n",
       "      <td id=\"T_474b5_row0_col13\" class=\"data row0 col13\" >92.440000</td>\n",
       "      <td id=\"T_474b5_row0_col14\" class=\"data row0 col14\" >41.920000</td>\n",
       "      <td id=\"T_474b5_row0_col15\" class=\"data row0 col15\" >22.370000</td>\n",
       "      <td id=\"T_474b5_row0_col16\" class=\"data row0 col16\" >55.320000</td>\n",
       "      <td id=\"T_474b5_row0_col17\" class=\"data row0 col17\" >22.290000</td>\n",
       "      <td id=\"T_474b5_row0_col18\" class=\"data row0 col18\" >0-0</td>\n",
       "      <td id=\"T_474b5_row0_col19\" class=\"data row0 col19\" >77.690000</td>\n",
       "      <td id=\"T_474b5_row0_col20\" class=\"data row0 col20\" >44.660000</td>\n",
       "      <td id=\"T_474b5_row0_col21\" class=\"data row0 col21\" >77.610000</td>\n",
       "      <td id=\"T_474b5_row0_col22\" class=\"data row0 col22\" >54.210000</td>\n",
       "      <td id=\"T_474b5_row0_col23\" class=\"data row0 col23\" >78.290000</td>\n",
       "      <td id=\"T_474b5_row0_col24\" class=\"data row0 col24\" >77.350000</td>\n",
       "      <td id=\"T_474b5_row0_col25\" class=\"data row0 col25\" >52.460000</td>\n",
       "      <td id=\"T_474b5_row0_col26\" class=\"data row0 col26\" >43.720000</td>\n",
       "      <td id=\"T_474b5_row0_col27\" class=\"data row0 col27\" >17.110000</td>\n",
       "      <td id=\"T_474b5_row0_col28\" class=\"data row0 col28\" >81.260000</td>\n",
       "      <td id=\"T_474b5_row0_col29\" class=\"data row0 col29\" >96.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_474b5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_474b5_row1_col0\" class=\"data row1 col0\" >Usa</td>\n",
       "      <td id=\"T_474b5_row1_col1\" class=\"data row1 col1\" >Los Angeles FC</td>\n",
       "      <td id=\"T_474b5_row1_col2\" class=\"data row1 col2\" >Sporting KC</td>\n",
       "      <td id=\"T_474b5_row1_col3\" class=\"data row1 col3\" >60.910000</td>\n",
       "      <td id=\"T_474b5_row1_col4\" class=\"data row1 col4\" >19.080000</td>\n",
       "      <td id=\"T_474b5_row1_col5\" class=\"data row1 col5\" >19.840000</td>\n",
       "      <td id=\"T_474b5_row1_col6\" class=\"data row1 col6\" >2-1</td>\n",
       "      <td id=\"T_474b5_row1_col7\" class=\"data row1 col7\" >79.990000</td>\n",
       "      <td id=\"T_474b5_row1_col8\" class=\"data row1 col8\" >80.750000</td>\n",
       "      <td id=\"T_474b5_row1_col9\" class=\"data row1 col9\" >38.920000</td>\n",
       "      <td id=\"T_474b5_row1_col10\" class=\"data row1 col10\" >92.520000</td>\n",
       "      <td id=\"T_474b5_row1_col11\" class=\"data row1 col11\" >78.360000</td>\n",
       "      <td id=\"T_474b5_row1_col12\" class=\"data row1 col12\" >40.160000</td>\n",
       "      <td id=\"T_474b5_row1_col13\" class=\"data row1 col13\" >59.630000</td>\n",
       "      <td id=\"T_474b5_row1_col14\" class=\"data row1 col14\" >73.110000</td>\n",
       "      <td id=\"T_474b5_row1_col15\" class=\"data row1 col15\" >56.760000</td>\n",
       "      <td id=\"T_474b5_row1_col16\" class=\"data row1 col16\" >29.220000</td>\n",
       "      <td id=\"T_474b5_row1_col17\" class=\"data row1 col17\" >11.340000</td>\n",
       "      <td id=\"T_474b5_row1_col18\" class=\"data row1 col18\" >1-0</td>\n",
       "      <td id=\"T_474b5_row1_col19\" class=\"data row1 col19\" >85.980000</td>\n",
       "      <td id=\"T_474b5_row1_col20\" class=\"data row1 col20\" >68.100000</td>\n",
       "      <td id=\"T_474b5_row1_col21\" class=\"data row1 col21\" >40.560000</td>\n",
       "      <td id=\"T_474b5_row1_col22\" class=\"data row1 col22\" >84.470000</td>\n",
       "      <td id=\"T_474b5_row1_col23\" class=\"data row1 col23\" >31.020000</td>\n",
       "      <td id=\"T_474b5_row1_col24\" class=\"data row1 col24\" >92.760000</td>\n",
       "      <td id=\"T_474b5_row1_col25\" class=\"data row1 col25\" >77.920000</td>\n",
       "      <td id=\"T_474b5_row1_col26\" class=\"data row1 col26\" >74.040000</td>\n",
       "      <td id=\"T_474b5_row1_col27\" class=\"data row1 col27\" >44.690000</td>\n",
       "      <td id=\"T_474b5_row1_col28\" class=\"data row1 col28\" >50.600000</td>\n",
       "      <td id=\"T_474b5_row1_col29\" class=\"data row1 col29\" >80.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_474b5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_474b5_row2_col0\" class=\"data row2 col0\" >Usa</td>\n",
       "      <td id=\"T_474b5_row2_col1\" class=\"data row2 col1\" >Vancouver</td>\n",
       "      <td id=\"T_474b5_row2_col2\" class=\"data row2 col2\" >Seattle</td>\n",
       "      <td id=\"T_474b5_row2_col3\" class=\"data row2 col3\" >56.900000</td>\n",
       "      <td id=\"T_474b5_row2_col4\" class=\"data row2 col4\" >25.280000</td>\n",
       "      <td id=\"T_474b5_row2_col5\" class=\"data row2 col5\" >17.800000</td>\n",
       "      <td id=\"T_474b5_row2_col6\" class=\"data row2 col6\" >1-1</td>\n",
       "      <td id=\"T_474b5_row2_col7\" class=\"data row2 col7\" >82.180000</td>\n",
       "      <td id=\"T_474b5_row2_col8\" class=\"data row2 col8\" >74.700000</td>\n",
       "      <td id=\"T_474b5_row2_col9\" class=\"data row2 col9\" >43.080000</td>\n",
       "      <td id=\"T_474b5_row2_col10\" class=\"data row2 col10\" >77.110000</td>\n",
       "      <td id=\"T_474b5_row2_col11\" class=\"data row2 col11\" >51.660000</td>\n",
       "      <td id=\"T_474b5_row2_col12\" class=\"data row2 col12\" >70.470000</td>\n",
       "      <td id=\"T_474b5_row2_col13\" class=\"data row2 col13\" >85.650000</td>\n",
       "      <td id=\"T_474b5_row2_col14\" class=\"data row2 col14\" >51.880000</td>\n",
       "      <td id=\"T_474b5_row2_col15\" class=\"data row2 col15\" >55.420000</td>\n",
       "      <td id=\"T_474b5_row2_col16\" class=\"data row2 col16\" >35.020000</td>\n",
       "      <td id=\"T_474b5_row2_col17\" class=\"data row2 col17\" >8.720000</td>\n",
       "      <td id=\"T_474b5_row2_col18\" class=\"data row2 col18\" >1-0</td>\n",
       "      <td id=\"T_474b5_row2_col19\" class=\"data row2 col19\" >90.440000</td>\n",
       "      <td id=\"T_474b5_row2_col20\" class=\"data row2 col20\" >64.140000</td>\n",
       "      <td id=\"T_474b5_row2_col21\" class=\"data row2 col21\" >43.740000</td>\n",
       "      <td id=\"T_474b5_row2_col22\" class=\"data row2 col22\" >76.480000</td>\n",
       "      <td id=\"T_474b5_row2_col23\" class=\"data row2 col23\" >50.730000</td>\n",
       "      <td id=\"T_474b5_row2_col24\" class=\"data row2 col24\" >83.660000</td>\n",
       "      <td id=\"T_474b5_row2_col25\" class=\"data row2 col25\" >60.540000</td>\n",
       "      <td id=\"T_474b5_row2_col26\" class=\"data row2 col26\" >54.070000</td>\n",
       "      <td id=\"T_474b5_row2_col27\" class=\"data row2 col27\" >23.850000</td>\n",
       "      <td id=\"T_474b5_row2_col28\" class=\"data row2 col28\" >72.730000</td>\n",
       "      <td id=\"T_474b5_row2_col29\" class=\"data row2 col29\" >93.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eee15553d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft1, ftx, ft2, ft_score = [], [], [], []\n",
    "over_15, over_25, under_35, under_45, btts = [], [], [], [], []\n",
    "ht1, htx, ht2, ht_score, ht_over05, ht_under15 = [], [], [], [], [], []\n",
    "ho05, ao05, ho15, ao15, hu25, au25 = [], [], [], [], [], []\n",
    "\n",
    "# Helper function to calculate total goals for each score\n",
    "def total_goals(i, j):\n",
    "    return i + j\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_matrix = full_time_matrices[i]\n",
    "    ht_matrix = half_time_matrices[i]\n",
    "\n",
    "    ft1.append(round(np.sum(np.tril(my_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    ftx.append(round(np.sum(np.diag(my_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ft2.append(round(np.sum(np.triu(my_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "    \n",
    "    max_score = np.unravel_index(np.argmax(my_matrix), my_matrix.shape) # Find the index of the maximum score\n",
    "    home_goals, away_goals = max_score\n",
    "    ft_score.append(f\"{home_goals}-{away_goals}\") # Format the score as 'home-away'\n",
    "\n",
    "    # Calculate the probabilities\n",
    "    over_15.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 1.5]) * 100, 2))\n",
    "    over_25.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 2.5]) * 100, 2))\n",
    "    under_35.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 3.5]) * 100, 2))\n",
    "    under_45.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 4.5]) * 100, 2))\n",
    "\n",
    "    # Calculate BTTS (both teams to score and goals != 0)\n",
    "    btts.append(round(np.sum([my_matrix[i, j] for i in range(1, my_matrix.shape[0]) for j in range(1, my_matrix.shape[1])]) * 100, 2)) \n",
    "\n",
    "    # Calculate statistics for Half Time\n",
    "    ht1.append(round(np.sum(np.tril(ht_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    htx.append(round(np.sum(np.diag(ht_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ht2.append(round(np.sum(np.triu(ht_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "\n",
    "    ht_max_score = np.unravel_index(np.argmax(ht_matrix), ht_matrix.shape) # Find the index of the maximum score\n",
    "    ht_hogs, ht_awgs = ht_max_score\n",
    "    ht_score.append(f\"{ht_hogs}-{ht_awgs}\") # Format the score as 'home-away'\n",
    "\n",
    "    ht_over05.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) > 0.5]) * 100, 2))   \n",
    "    ht_under15.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) < 1.5]) * 100, 2)) \n",
    "\n",
    "    ho05.append(round(np.sum(my_matrix[1:,:]) * 100, 2))\n",
    "    ao05.append(round(np.sum(my_matrix[:,1:]) * 100, 2))\n",
    "    ho15.append(round(np.sum(my_matrix[2:,:]) * 100, 2))\n",
    "    ao15.append(round(np.sum(my_matrix[:,2:]) * 100, 2))\n",
    "    hu25.append(round(np.sum(my_matrix[:3,:]) * 100, 2))\n",
    "    au25.append(round(np.sum(my_matrix[:,:3]) * 100, 2))\n",
    "    \n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "final_results = pd.DataFrame({\n",
    "    'League': next_matches['League'], 'Home': next_matches['Home'], 'Away': next_matches['Away'],\n",
    "    'FT1': ft1, 'FTX': ftx, 'FT2': ft2, 'FTR': ft_score,\n",
    "    'DC1X': [x + y for x, y in zip(ft1, ftx)], 'DC12': [x + y for x, y in zip(ft1, ft2)], 'DCX2': [x + y for x, y in zip(ftx, ft2)],\n",
    "    '1.5O': over_15, '2.5O': over_25, '3.5U': under_35, '4.5U': under_45, 'BTTS': btts,\n",
    "    'HT1': ht1, 'HTX': htx, 'HT2': ht2, 'HTR': ht_score,\n",
    "    'HTDC1X': [x + y for x, y in zip(ht1, htx)], 'HTDC12': [x + y for x, y in zip(ht1, ht2)], 'HTDCX2': [x + y for x, y in zip(htx, ht2)],\n",
    "    'HT0.5O': ht_over05, 'HT1.5U': ht_under15, 'H0.5O':ho05, 'A0.5O':ao05, 'H1.5O':ho15, 'A1.5O':ao15, 'H2.5U':hu25, 'A2.5U':au25\n",
    "})\n",
    "\n",
    "# Function to highlight values higher than threshold\n",
    "def highlight_values(value):\n",
    "    if isinstance(value, str):\n",
    "        return ''  # Return empty string for NaN values\n",
    "    elif value > threshold:\n",
    "    #color = 'red'\n",
    "        return 'background-color: red'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply the style\n",
    "with pd.option_context('display.precision', 2):\n",
    "    styled_df = final_results.style.applymap(highlight_values)\n",
    "styled_df.to_excel(given_date + \".xlsx\", index = False)\n",
    "# Display the styled DataFrame\n",
    "from IPython.display import display, HTML\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
